{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c986d23",
   "metadata": {},
   "source": [
    "# Mini-Project 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd5882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api  # load \n",
    "from gensim.similarities import Similarity #\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff65f1",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40d26a",
   "metadata": {},
   "source": [
    "### Load the word2vec-google-news-300 pretrained embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642be64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_300 =api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9492f4a",
   "metadata": {},
   "source": [
    "### Loading synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b533ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = pd.read_csv(\"synonyms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf61da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enormously</td>\n",
       "      <td>tremendously</td>\n",
       "      <td>appropriately</td>\n",
       "      <td>uniquely</td>\n",
       "      <td>tremendously</td>\n",
       "      <td>decidedly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>provisions</td>\n",
       "      <td>stipulations</td>\n",
       "      <td>stipulations</td>\n",
       "      <td>interrelations</td>\n",
       "      <td>jurisdictions</td>\n",
       "      <td>interpretations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haphazardly</td>\n",
       "      <td>randomly</td>\n",
       "      <td>dangerously</td>\n",
       "      <td>densely</td>\n",
       "      <td>randomly</td>\n",
       "      <td>linearly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prominent</td>\n",
       "      <td>conspicuous</td>\n",
       "      <td>battered</td>\n",
       "      <td>ancient</td>\n",
       "      <td>mysterious</td>\n",
       "      <td>conspicuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zenith</td>\n",
       "      <td>pinnacle</td>\n",
       "      <td>completion</td>\n",
       "      <td>pinnacle</td>\n",
       "      <td>outset</td>\n",
       "      <td>decline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question        answer              0               1              2  \\\n",
       "0   enormously  tremendously  appropriately        uniquely   tremendously   \n",
       "1   provisions  stipulations   stipulations  interrelations  jurisdictions   \n",
       "2  haphazardly      randomly    dangerously         densely       randomly   \n",
       "3    prominent   conspicuous       battered         ancient     mysterious   \n",
       "4       zenith      pinnacle     completion        pinnacle         outset   \n",
       "\n",
       "                 3  \n",
       "0        decidedly  \n",
       "1  interpretations  \n",
       "2         linearly  \n",
       "3      conspicuous  \n",
       "4          decline  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803243dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['enormously' 'tremendously' 'appropriately' 'uniquely' 'tremendously'\n",
      "  'decidedly']\n",
      " ['provisions' 'stipulations' 'stipulations' 'interrelations'\n",
      "  'jurisdictions' 'interpretations']\n",
      " ['haphazardly' 'randomly' 'dangerously' 'densely' 'randomly' 'linearly']\n",
      " ['prominent' 'conspicuous' 'battered' 'ancient' 'mysterious'\n",
      "  'conspicuous']\n",
      " ['zenith' 'pinnacle' 'completion' 'pinnacle' 'outset' 'decline']\n",
      " ['flawed' 'imperfect' 'tiny' 'imperfect' 'lustrous' 'crude']\n",
      " ['urgently' 'desperately' 'typically' 'conceivably' 'tentatively'\n",
      "  'desperately']\n",
      " ['consumed' 'eaten' 'bred' 'caught' 'eaten' 'supplied']\n",
      " ['advent' 'coming' 'coming' 'arrest' 'financing' 'stability']\n",
      " ['concisely' 'succinctly' 'powerfully' 'positively' 'freely'\n",
      "  'succinctly']\n",
      " ['salutes' 'greetings' 'information' 'ceremonies' 'greetings'\n",
      "  'privileges']\n",
      " ['solitary' 'alone' 'alert' 'restless' 'alone' 'fearless']\n",
      " ['hasten' 'accelerate' 'permit' 'determine' 'accelerate' 'accompany']\n",
      " ['perseverance' 'endurance' 'endurance' 'skill' 'generosity'\n",
      "  'disturbance']\n",
      " ['fanciful' 'imaginative' 'familiar' 'imaginative' 'apparent' 'logical']\n",
      " ['showed' 'demonstrated' 'demonstrated' 'published' 'repeated'\n",
      "  'postponed']\n",
      " ['constantly' 'continually' 'instantly' 'continually' 'rapidly'\n",
      "  'accidentally']\n",
      " ['issues' 'subjects' 'training' 'salaries' 'subjects' 'benefits']\n",
      " ['furnish' 'supply' 'supply' 'impress' 'protect' 'advise']\n",
      " ['costly' 'expensive' 'expensive' 'beautiful' 'popular' 'complicated']\n",
      " ['recognized' 'acknowledged' 'successful' 'depicted' 'acknowledged'\n",
      "  'welcomed']\n",
      " ['spot' 'location' 'climate' 'latitude' 'sea' 'location']\n",
      " ['make' 'earn' 'earn' 'print' 'trade' 'borrow']\n",
      " ['often' 'frequently' 'definitely' 'frequently' 'chemically' 'hardly']\n",
      " ['easygoing' 'relaxed' 'frontier' 'boring' 'farming' 'relaxed']\n",
      " ['debate' 'argument' 'war' 'argument' 'election' 'competition']\n",
      " ['narrow' 'thin' 'clear' 'freezing' 'thin' 'poisonous']\n",
      " ['arranged' 'planned' 'planned' 'explained' 'studied' 'discarded']\n",
      " ['infinite' 'limitless' 'limitless' 'relative' 'unusual' 'structural']\n",
      " ['showy' 'striking' 'striking' 'prickly' 'entertaining' 'incidental']\n",
      " ['levied' 'imposed' 'imposed' 'believed' 'requested' 'correlated']\n",
      " ['deftly' 'skillfully' 'skillfully' 'prudently' 'occasionally'\n",
      "  'humorously']\n",
      " ['distribute' 'circulate' 'commercialize' 'circulate' 'research'\n",
      "  'acknowledge']\n",
      " ['discrepancies' 'differences' 'weights' 'deposits' 'wavelengths'\n",
      "  'differences']\n",
      " ['prolific' 'productive' 'productive' 'serious' 'capable' 'promising']\n",
      " ['unmatched' 'unequaled' 'unrecognized' 'unequaled' 'alienated'\n",
      "  'emulated']\n",
      " ['peculiarly' 'uniquely' 'partly' 'uniquely' 'patriotically'\n",
      "  'suspiciously']\n",
      " ['hue' 'color' 'glare' 'contrast' 'color' 'scent']\n",
      " ['hind' 'rear' 'curved' 'muscular' 'hairy' 'rear']\n",
      " ['highlight' 'accentuate' 'alter' 'imitate' 'accentuate' 'restore']\n",
      " ['hastily' 'hurriedly' 'hurriedly' 'shrewdly' 'habitually'\n",
      "  'chronologically']\n",
      " ['temperate' 'mild' 'cold' 'mild' 'short' 'windy']\n",
      " ['grin' 'smile' 'exercise' 'rest' 'joke' 'smile']\n",
      " ['verbally' 'orally' 'orally' 'overtly' 'fittingly' 'verbosely']\n",
      " ['physician' 'doctor' 'chemist' 'pharmacist' 'nurse' 'doctor']\n",
      " ['essentially' 'basically' 'possibly' 'eagerly' 'basically' 'ordinarily']\n",
      " ['keen' 'sharp' 'useful' 'simple' 'famous' 'sharp']\n",
      " ['situated' 'positioned' 'rotating' 'isolated' 'emptying' 'positioned']\n",
      " ['principal' 'major' 'most' 'numerous' 'major' 'exceptional']\n",
      " ['slowly' 'gradually' 'rarely' 'gradually' 'effectively' 'continuously']\n",
      " ['built' 'constructed' 'constructed' 'proposed' 'financed' 'organized']\n",
      " ['tasks' 'jobs' 'customers' 'materials' 'shops' 'jobs']\n",
      " ['unlikely' 'improbable' 'improbable' 'disagreeable' 'different'\n",
      "  'unpopular']\n",
      " ['halfheartedly' 'apathetically' 'customarily' 'bipartisanly'\n",
      "  'apathetically' 'unconventionally']\n",
      " ['annals' 'chronicles' 'homes' 'trails' 'chronicles' 'songs']\n",
      " ['wildly' 'furiously' 'distinctively' 'mysteriously' 'abruptly'\n",
      "  'furiously']\n",
      " ['hailed' 'acclaimed' 'judged' 'acclaimed' 'remembered' 'addressed']\n",
      " ['command' 'mastery' 'observation' 'love' 'awareness' 'mastery']\n",
      " ['concocted' 'devised' 'devised' 'cleaned' 'requested' 'supervised']\n",
      " ['prospective' 'potential' 'particular' 'prudent' 'potential'\n",
      "  'prominent']\n",
      " ['generally' 'broadly' 'descriptively' 'broadly' 'controversially'\n",
      "  'accurately']\n",
      " ['sustained' 'prolonged' 'prolonged' 'refined' 'lowered' 'analyzed']\n",
      " ['perilous' 'dangerous' 'binding' 'exciting' 'offensive' 'dangerous']\n",
      " ['tranquillity' 'peacefulness' 'peacefulness' 'harshness' 'weariness'\n",
      "  'happiness']\n",
      " ['dissipate' 'disperse' 'disperse' 'isolate' 'disguise' 'photograph']\n",
      " ['primarily' 'chiefly' 'occasionally' 'cautiously' 'consistently'\n",
      "  'chiefly']\n",
      " ['colloquial' 'conversational' 'recorded' 'misunderstood' 'incorrect'\n",
      "  'conversational']\n",
      " ['resolved' 'settled' 'publicized' 'forgotten' 'settled' 'examined']\n",
      " ['feasible' 'possible' 'permitted' 'possible' 'equitable' 'evident']\n",
      " ['expeditiously' 'rapidly' 'frequently' 'actually' 'rapidly'\n",
      "  'repeatedly']\n",
      " ['percentage' 'proportion' 'volume' 'sample' 'proportion' 'profit']\n",
      " ['terminated' 'ended' 'ended' 'posed' 'postponed' 'evaluated']\n",
      " ['uniform' 'alike' 'hard' 'complex' 'alike' 'sharp']\n",
      " ['figure' 'solve' 'list' 'solve' 'divide' 'express']\n",
      " ['sufficient' 'enough' 'recent' 'physiological' 'enough' 'valuable']\n",
      " ['fashion' 'manner' 'ration' 'fathom' 'craze' 'manner']\n",
      " ['marketed' 'sold' 'frozen' 'sold' 'sweetened' 'diluted']\n",
      " ['bigger' 'larger' 'steadier' 'closer' 'larger' 'better']\n",
      " ['roots' 'origins' 'origins' 'rituals' 'cure' 'function']\n",
      " ['normally' 'ordinarily' 'haltingly' 'ordinarily' 'permanently'\n",
      "  'periodically']]\n"
     ]
    }
   ],
   "source": [
    "# list = synonyms.to_numpy()\n",
    "# print(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a172a",
   "metadata": {},
   "source": [
    "## Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057a1df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :enormously ==> Answer: appropriately\n",
      "0.16631226\n",
      "Question :enormously ==> Answer: uniquely\n",
      "0.34684694\n",
      "Question :enormously ==> Answer: tremendously\n",
      "0.8185792\n",
      "Question :enormously ==> Answer: decidedly\n",
      "0.26498795\n"
     ]
    }
   ],
   "source": [
    "# todo for loop throgh all questienions - done\n",
    "for word  in range(2,6) :\n",
    "#    if (word == 2):\n",
    "    print(f'Question :{synonyms.iloc[0,:][0]} ==> Answer: {synonyms.iloc[0,:][word]}')\n",
    "#  todo   list()\n",
    "# todo print the word it self and rthe cosie\n",
    "    print (word2vec_300.similarity(synonyms.iloc[0,:][0], synonyms.iloc[0,:][word]  ))\n",
    "#  todo  find the max in list => it is our answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ef5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"word2vec-google-news-300-details.csv\", \"w\")\n",
    "f.write(\"Our Result Data Set\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e933abff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21952/3296790947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msynonyms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "synonyms.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b4e69f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question word :enormously\n",
      "Question :enormously ==> Answer: appropriately\n",
      "0.16631226\n",
      "Question :enormously ==> Answer: uniquely\n",
      "0.34684694\n",
      "Question :enormously ==> Answer: tremendously\n",
      "0.8185792\n",
      "Question :enormously ==> Answer: decidedly\n",
      "0.26498795\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"set\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21952/349070800.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mword_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msynonyms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2vec_300\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynonyms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msynonyms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"THE WORD FOUND IS: \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mword_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"set\") to str"
     ]
    }
   ],
   "source": [
    "f = open(\"word2vec-google-news-300-details.csv\", \"a\")\n",
    "\n",
    "rows = synonyms.shape[0]\n",
    "columns = synonyms.shape[1]\n",
    "max = 0\n",
    "word_result = \"\"\n",
    "for row in range(0, synonyms.shape[0]):\n",
    "    print(f'Question word :{synonyms.iloc[row,:][0]}')\n",
    "    question_word = {synonyms.iloc[row,:][0]}\n",
    "    f.write(repr(question_word) + \",\")\n",
    "    for word in range(2, synonyms.shape[1]):\n",
    "        print(f'Question :{synonyms.iloc[row,:][0]} ==> Answer: {synonyms.iloc[row,:][word]}')  \n",
    "        #correct_word = {synonyms.iloc[row,:][word]}\n",
    "        #f.write(repr(correct_word) + \",\")\n",
    "        \n",
    "#         max = 0.2\n",
    "#         if(word > max)\n",
    "#         max =\n",
    "        cosine_value = word2vec_300.similarity(synonyms.iloc[row,:][0], synonyms.iloc[row,:][word])\n",
    "        if cosine_value > max:\n",
    "            max = cosine_value\n",
    "            word_result = {synonyms.iloc[row,:][word]}\n",
    "        print(word2vec_300.similarity(synonyms.iloc[row,:][0], synonyms.iloc[row,:][word]  ))\n",
    "    print(\"THE WORD FOUND IS: \"+ word_result)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e01a1d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vehicle', 0.7821096181869507),\n",
       " ('cars', 0.7423830032348633),\n",
       " ('SUV', 0.7160962224006653),\n",
       " ('minivan', 0.6907036304473877),\n",
       " ('truck', 0.6735789775848389),\n",
       " ('Car', 0.6677608489990234),\n",
       " ('Ford_Focus', 0.6673202514648438),\n",
       " ('Honda_Civic', 0.6626849174499512),\n",
       " ('Jeep', 0.651133120059967),\n",
       " ('pickup_truck', 0.6441437602043152)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_300.most_similar(\"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8527f80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_300.similarity('car', 'car'  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec91378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43913448"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_300.similarity('car', 'Auto'  ) #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0616037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       question        answer              0               1              2  \\\n",
      "0    enormously  tremendously  appropriately        uniquely   tremendously   \n",
      "1    provisions  stipulations   stipulations  interrelations  jurisdictions   \n",
      "2   haphazardly      randomly    dangerously         densely       randomly   \n",
      "3     prominent   conspicuous       battered         ancient     mysterious   \n",
      "4        zenith      pinnacle     completion        pinnacle         outset   \n",
      "..          ...           ...            ...             ...            ...   \n",
      "75      fashion        manner         ration          fathom          craze   \n",
      "76     marketed          sold         frozen            sold      sweetened   \n",
      "77       bigger        larger       steadier          closer         larger   \n",
      "78        roots       origins        origins         rituals           cure   \n",
      "79     normally    ordinarily      haltingly      ordinarily    permanently   \n",
      "\n",
      "                  3  \n",
      "0         decidedly  \n",
      "1   interpretations  \n",
      "2          linearly  \n",
      "3       conspicuous  \n",
      "4           decline  \n",
      "..              ...  \n",
      "75           manner  \n",
      "76          diluted  \n",
      "77           better  \n",
      "78         function  \n",
      "79     periodically  \n",
      "\n",
      "[80 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96274c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
